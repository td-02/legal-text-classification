{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6723483,"sourceType":"datasetVersion","datasetId":3873453}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch torchvision scikit-learn","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:01.717216Z","iopub.execute_input":"2024-09-05T17:20:01.71764Z","iopub.status.idle":"2024-09-05T17:20:16.090154Z","shell.execute_reply.started":"2024-09-05T17:20:01.717584Z","shell.execute_reply":"2024-09-05T17:20:16.089055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nfrom sklearn.utils.class_weight import compute_class_weight\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:16.092029Z","iopub.execute_input":"2024-09-05T17:20:16.092346Z","iopub.status.idle":"2024-09-05T17:20:22.030633Z","shell.execute_reply.started":"2024-09-05T17:20:16.092305Z","shell.execute_reply":"2024-09-05T17:20:22.029806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path = '/kaggle/input/legal-text-classification-dataset/legal_text_classification.csv'\ndf = pd.read_csv(dataset_path)\n\ndf.dropna(inplace=True)\n\nlabel_encoder = LabelEncoder()\ndf['case_outcome_encoded'] = label_encoder.fit_transform(df['case_outcome'])\n\nclass_counts = df['case_outcome_encoded'].value_counts()\nprint(\"Class distribution in training data:\\n\", class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:22.031823Z","iopub.execute_input":"2024-09-05T17:20:22.032388Z","iopub.status.idle":"2024-09-05T17:20:23.364944Z","shell.execute_reply.started":"2024-09-05T17:20:22.032344Z","shell.execute_reply":"2024-09-05T17:20:23.363866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['case_outcome_encoded'], random_state=42)\n\nmajority_class_size = train_df['case_outcome_encoded'].value_counts().max()\ntrain_df_balanced = train_df.groupby('case_outcome_encoded', group_keys=False)\\\n                            .apply(lambda x: x.sample(majority_class_size, replace=True)).reset_index(drop=True)\n\nbalanced_class_counts = train_df_balanced['case_outcome_encoded'].value_counts()\nprint(\"Class distribution after oversampling:\\n\", balanced_class_counts)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:23.367481Z","iopub.execute_input":"2024-09-05T17:20:23.36793Z","iopub.status.idle":"2024-09-05T17:20:23.424371Z","shell.execute_reply.started":"2024-09-05T17:20:23.367882Z","shell.execute_reply":"2024-09-05T17:20:23.423375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LegalDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        case_text = str(self.data.iloc[index]['case_text'])\n        case_outcome = self.data.iloc[index]['case_outcome_encoded']\n\n        encoding = self.tokenizer.encode_plus(\n            case_text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(case_outcome, dtype=torch.long)\n        }\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:23.425692Z","iopub.execute_input":"2024-09-05T17:20:23.426006Z","iopub.status.idle":"2024-09-05T17:20:23.433663Z","shell.execute_reply.started":"2024-09-05T17:20:23.425971Z","shell.execute_reply":"2024-09-05T17:20:23.432745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"legalbert_model_name = 'nlpaueb/legal-bert-base-uncased'\n\ntokenizer = BertTokenizer.from_pretrained(legalbert_model_name)\nmodel = BertForSequenceClassification.from_pretrained(legalbert_model_name, num_labels=len(label_encoder.classes_))","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:23.434871Z","iopub.execute_input":"2024-09-05T17:20:23.435184Z","iopub.status.idle":"2024-09-05T17:20:27.634506Z","shell.execute_reply.started":"2024-09-05T17:20:23.435152Z","shell.execute_reply":"2024-09-05T17:20:27.633616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 256\nbatch_size = 16\nepochs = 6\nlearning_rate = 2e-5\nweight_decay = 0.01","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:27.635866Z","iopub.execute_input":"2024-09-05T17:20:27.636173Z","iopub.status.idle":"2024-09-05T17:20:27.640591Z","shell.execute_reply.started":"2024-09-05T17:20:27.636141Z","shell.execute_reply":"2024-09-05T17:20:27.639587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = LegalDataset(train_df_balanced, tokenizer, max_length)\nval_dataset = LegalDataset(val_df, tokenizer, max_length)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:27.641774Z","iopub.execute_input":"2024-09-05T17:20:27.642057Z","iopub.status.idle":"2024-09-05T17:20:27.654269Z","shell.execute_reply.started":"2024-09-05T17:20:27.642026Z","shell.execute_reply":"2024-09-05T17:20:27.653488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_df_balanced['case_outcome_encoded']), y=train_df_balanced['case_outcome_encoded'])\nclass_weights = torch.tensor(class_weights, dtype=torch.float)\n\nloss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:27.6552Z","iopub.execute_input":"2024-09-05T17:20:27.655467Z","iopub.status.idle":"2024-09-05T17:20:27.694202Z","shell.execute_reply.started":"2024-09-05T17:20:27.655437Z","shell.execute_reply":"2024-09-05T17:20:27.693512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\ntotal_steps = len(train_loader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:27.696543Z","iopub.execute_input":"2024-09-05T17:20:27.697041Z","iopub.status.idle":"2024-09-05T17:20:28.297907Z","shell.execute_reply.started":"2024-09-05T17:20:27.697008Z","shell.execute_reply":"2024-09-05T17:20:28.296943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, data_loader, optimizer, device, scheduler):\n    model = model.train()\n    losses = []\n    correct_predictions = 0\n\n    for d in tqdm(data_loader):\n        input_ids = d['input_ids'].to(device)\n        attention_mask = d['attention_mask'].to(device)\n        labels = d['labels'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        losses.append(loss.item())\n        preds = torch.argmax(logits, dim=1)\n        correct_predictions += torch.sum(preds == labels).item()\n\n    return correct_predictions / len(data_loader.dataset), np.mean(losses)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:28.2991Z","iopub.execute_input":"2024-09-05T17:20:28.299555Z","iopub.status.idle":"2024-09-05T17:20:28.307237Z","shell.execute_reply.started":"2024-09-05T17:20:28.29952Z","shell.execute_reply":"2024-09-05T17:20:28.306366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_model(model, data_loader, device):\n    model = model.eval()\n    losses = []\n    correct_predictions = 0\n    y_preds = []\n    y_true = []\n\n    with torch.no_grad():\n        for d in tqdm(data_loader):\n            input_ids = d['input_ids'].to(device)\n            attention_mask = d['attention_mask'].to(device)\n            labels = d['labels'].to(device)\n\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            logits = outputs.logits\n\n            losses.append(loss.item())\n            preds = torch.argmax(logits, dim=1)\n            correct_predictions += torch.sum(preds == labels).item()\n            y_preds.extend(preds.cpu().numpy())\n            y_true.extend(labels.cpu().numpy())\n\n    report = classification_report(y_true, y_preds, target_names=label_encoder.classes_)\n    print(report)\n    return correct_predictions / len(data_loader.dataset), np.mean(losses)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:28.308456Z","iopub.execute_input":"2024-09-05T17:20:28.308827Z","iopub.status.idle":"2024-09-05T17:20:28.317918Z","shell.execute_reply.started":"2024-09-05T17:20:28.30878Z","shell.execute_reply":"2024-09-05T17:20:28.317022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nfor epoch in range(epochs):\n    print(f'Epoch {epoch+1}/{epochs}')\n    print('-' * 20)\n\n    train_acc, train_loss = train_epoch(model, train_loader, optimizer, device, scheduler)\n    print(f'Train loss {train_loss}, accuracy {train_acc}')\n\n    val_acc, val_loss = eval_model(model, val_loader, device)\n    print(f'Validation loss {val_loss}, accuracy {val_acc}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T17:20:28.319036Z","iopub.execute_input":"2024-09-05T17:20:28.319823Z"},"trusted":true},"execution_count":null,"outputs":[]}]}